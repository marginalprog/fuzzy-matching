# Анализ результатов тестирования производительности

## Общий обзор

Наиболее быстрый алгоритм: **Базовая конфигурация без транслитерации (RATIO)** со следующими показателями:
- 100 записей: 42921.65 записей/сек
- 500 записей: 21686.52 записей/сек
- 1000 записей: 13067.63 записей/сек

Наиболее эффективный алгоритм по количеству найденных совпадений: **PARTIAL_RATIO** (459 совпадений на 1000 записях)

## Описание конфигураций

### Базовая без транслитерации
- Алгоритм RATIO (по умолчанию)
- Блокировка по email
- Порог схожести 0.7
- Транслитерация отключена
- Стандартные веса для всех полей

### Полная с транслитерацией
- Алгоритм RATIO (по умолчанию)
- Блокировка по email
- Порог схожести 0.7
- Транслитерация включена для всех текстовых полей
- Стандарт транслитерации "Passport"
- Автоопределение языка
- Нормализация имен

## Сравнение скорости обработки

| Размер данных | Конфигурация | Время (сек) | Совпадений | Скорость (записей/сек) |
|---------------|--------------|-------------|------------|----------------------|
| 100 | Базовая без транслитерации | 0.0024 | 44 | 42921.65 |
| 100 | Полная транслитерация | 0.0065 | 44 | 16364.18 |
| 100 | PARTIAL_RATIO без транслит. | 0.0027 | 45 | 37037.04 |
| 100 | TOKEN_SORT без транслит. | 0.0022 | 44 | 44820.52 |
| 500 | Базовая без транслитерации | 0.0223 | 213 | 21686.52 |
| 500 | Полная транслитерация | 0.0912 | 213 | 5441.95 |
| 500 | PARTIAL_RATIO без транслит. | 0.0279 | 224 | 17921.15 |
| 500 | TOKEN_SORT без транслит. | 0.0239 | 213 | 20920.50 |
| 1000 | Базовая без транслитерации | 0.0744 | 433 | 13067.63 |
| 1000 | Полная транслитерация | 0.3380 | 433 | 2786.14 |
| 1000 | PARTIAL_RATIO без транслит. | 0.0991 | 459 | 10090.82 |
| 1000 | TOKEN_SORT без транслит. | 0.0839 | 433 | 11917.76 |

## Влияние транслитерации

### Размер данных: 100
* Без транслитерации: 0.0024 сек
* С транслитерацией: 0.0065 сек
* Накладные расходы: 172.30%

### Размер данных: 500
* Без транслитерации: 0.0223 сек
* С транслитерацией: 0.0912 сек
* Накладные расходы: 308.36%

### Размер данных: 1000
* Без транслитерации: 0.0744 сек
* С транслитерацией: 0.3380 сек
* Накладные расходы: 354.03%

## Влияние блокировки

### Размер данных: 100
* С блокировкой: 0.0065 сек
* Без блокировки: 0.2484 сек
* Увеличение времени: 3747.49%

### Размер данных: 500
* С блокировкой: 0.0912 сек
* Без блокировки: 6.6025 сек
* Увеличение времени: 7140.91%

### Размер данных: 1000
* С блокировкой: 0.3380 сек
* Без блокировки: 28.1197 сек
* Увеличение времени: 8219.20%

## Сравнительный анализ алгоритмов

### Производительность
1. **Базовая конфигурация (RATIO)**:
   - Лучшая производительность на средних и больших наборах данных
   - Простой алгоритм Левенштейна
   - Наименьшие накладные расходы

2. **TOKEN_SORT**:
   - Хорошая производительность на малых наборах (лучшая для 100 записей)
   - Падение эффективности на больших наборах
   - Полезен для строк с переставленными словами

3. **PARTIAL_RATIO**:
   - Находит больше всего совпадений
   - Более низкая производительность
   - Лучший выбор для нечетких совпадений

4. **TOKEN_SET**:
   - Средняя производительность
   - Стабильные результаты
   - Хорош для текстов с разным порядком слов

### Рекомендации по выбору алгоритма

1. **Для высокой производительности**:
   - На больших наборах (>500 записей): RATIO (базовая конфигурация)
   - На малых наборах (<500 записей): TOKEN_SORT

2. **Для максимальной точности**:
   - PARTIAL_RATIO - когда важно найти все возможные совпадения
   - TOKEN_SET - для текстов с произвольным порядком слов

3. **Для сбалансированного подхода**:
   - Базовая конфигурация (RATIO) с настроенным порогом схожести
   - TOKEN_SORT для специфических случаев (имена, адреса)

## Анализ масштабируемости

### Методика расчета

Коэффициент масштабирования вычисляется по формуле:
```
Коэффициент = log(T2/T1) / log(N2/N1)
```
где:
- T1 - время выполнения для меньшего набора данных
- T2 - время выполнения для большего набора данных
- N1 - размер меньшего набора данных
- N2 - размер большего набора данных

### Результаты анализа

#### Базовая конфигурация без транслитерации:
- Время для 100 записей: 0.0024 сек
- Время для 1000 записей: 0.0744 сек
- Коэффициент масштабирования: 3.3
- Сложность алгоритма: O(n³.³)

#### Полная конфигурация с транслитерацией:
- Время для 100 записей: 0.0065 сек
- Время для 1000 записей: 0.3380 сек
- Коэффициент масштабирования: 5.9
- Сложность алгоритма: O(n⁵.⁹)

### Интерпретация результатов

1. **Без транслитерации**:
   - Рост времени выполнения кубический
   - При увеличении данных в 10 раз, время растет в ~31 раз
   - Приемлемо для наборов до 1000 записей

2. **С транслитерацией**:
   - Рост времени выполнения близок к O(n⁶)
   - При увеличении данных в 10 раз, время растет в ~52 раза
   - Рекомендуется использовать только для малых наборов данных

### Рекомендации по масштабированию

1. **Для больших наборов данных**:
   - Использовать конфигурацию без транслитерации
   - Применять блокировку по ключевым полям
   - Разбивать данные на меньшие наборы

2. **При необходимости транслитерации**:
   - Ограничить размер обрабатываемых данных
   - Использовать частичную транслитерацию
   - Применять параллельную обработку

![Сравнение времени выполнения](algorithm_time_comparison.png)

![Сравнение найденных совпадений](algorithm_matches_comparison.png)

![Эффективность алгоритмов](algorithm_efficiency_comparison.png)

![Влияние блокировки](blocking_impact.png)

